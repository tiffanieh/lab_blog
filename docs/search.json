[
  {
    "objectID": "posts/pytorch_tensor_post/index.html",
    "href": "posts/pytorch_tensor_post/index.html",
    "title": "PyTorch tutorial: tensor demo",
    "section": "",
    "text": "original tutorial link\ntensor: n-dimensional array; specialized data structure similar to arrays+matrices\n\nin PyTorch, used to encode inputs/outputs of a model+model parameters\nsimilar to ndarrays but run on GPUs or other accelerated hardware for computing\n\nTensor initialization — many ways:\n\ndirectly from data\ndata = [[1,2,],[3,4]]\nx_data = torch.tensor(data)\n#data type inferred\nfrom NumPy array\nnp_array = np.array(data)\nx_np = torch.from_numpy(np_array)\nfrom another tensor\n#argument tensor:\ndata = [[1,2,],[3,4]]\nx_data = torch.tensor(data)\n\n#new tensor:\nx_ones = torch.ones_like(x_data) # retains the properties of x_data\n\n#new tensor overriding properties:\nx_rand = torch.rand_like(x_data, dtype=torch.float)\n\nnew tensor retains properties (shape+datatype) of argument tensor unless explicitly overridden\n\nwith random or constant values:\nshape = (2, 3,)\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nhere shape is a tuple of tensor dimensions; determines dimensionality of output tensor\n\n\nTensor attributes: describe shape, datatype, and device on which they are stored\ntensor_name.shape\ntensor_name.dtype\ntensor_name.device\nTensor operations: over 100 including T, index, slicing, mathematical operations, linalg, random sampling, etc.\n\nTensor API very similar to NumPy API\nNumpy-like index+slice:\ntensor = torch.ones(4, 4)\ntensor[:,1] = 0\nJoining tensors: concatenate sequence of tensors along a given dimension using torch.cat\nt1 = torch.cat([tensor, tensor, tensor], dim=1)\nmultiplying tensors element-wise: use * operator or .mul() method\ntensor.mul(tensor)\n#or\ntensor*tensor\nmatrix multiplication: use @ operator with transposed matrix or .matmul(&lt;transpose&gt;) method\ntensor.matmul(tensor.T)\n#or\ntensor @ tensor.T\nin-place operations: any operations w/ a _ suffix\n#ex:\nx.copy_(y)\nx.t_()\n#change x in place\n\ntensor.add_(5) \n#change tensor in place\n\nhowever can cause issues when computing derivatives b/c of immediate loss of history\n\n\nBridge with NumPy: tensors on CPU+NumPy arrays can share underlying memory locations; changing one will change other\n\ntensor to np array\nt = torch.ones(5)\nn = t.numpy()\n\nchange in tensor reflects in np array\nt.add_(1)\n#n will change if t changes\n\nnp array to tensor\nn = np.ones(5)\nt = torch.from_numpy(n)\n\nchanges in np array reflects in tensor\nnp.add(n, 1, out=n)\n#t will change if n changes"
  },
  {
    "objectID": "posts/llm_summary_post/index.html",
    "href": "posts/llm_summary_post/index.html",
    "title": "LLM in molecular biology summary",
    "section": "",
    "text": "LLM in molecular biology summary\narticle link\nLarge language models\n\nLLM: a type of neural network that acquires the ability to generate text mirroring human language by scrutinizing vast amounts of textual data\n\nself-supervised — model learns to predict subsequent word in a sentence based on preceding words\ncan identify patterns and try to predict (i.e. advanced form of autocomplete)\n\n\nPrimary types of language models and their unique features:\n\nword grams: predict next word in a sentence based on frequency of word pairs/word bags (sets of words) — disregard context or word order (generates text that bear little resemblance to human text)\nCNNs: analyze text data by considering relationships between adjacent words in a fixed window; good at identifying local patterns, but fall short in capturing long-range dependencies or comprehending complex sentence structures\nLSTMs (long short-term memory networks): variant of RNNs; store+process information from earlier parts of a text; outperform CNNs in understanding context/managing long-range dependencies, but falter w/ complex sentences+long text\nattention mechanisms: enable models to concentrate on pertinent parts of input when making predictions; number of attention “heads” allow model to focus on different parts of previous text when predicting the next word\n\nlike revisiting key points/details; model refers back to relevant parts of text+incorporates info into current context\nex. transformers are a class of language models that implement attention mechanisms\n\nLLMs: models such as GPT-3 are transformers that leverage attention mechanisms+are trained on vast amounts of data; considerable size facilitates the learning of intricate patterns/relationships/context within text; represent the most advanced language models presently available, capable of generating more accurate+coherent responses across a broad spectrum of topics\n\n2 LLMs that use transformer architecture: BERT+GPT series\nBERT (bidirectional encoder representations from transformers): a series of LLMs by Google+open sourced\n\ntrained using masked language modeling (hide/“mask” some percentage of input tokens at random, then predict those masked tokens)\n\nforces model to understand context from both left/right sides of input (bidirectional)\n\nalso uses next sentence prediction task\nduring training, model is given pairs of sentences+has to predict whether second sentence in pair is the next sentence in the original document\n\nGPT (generative pretrained transformer): series of LLMs introduced by OpenAI\n\ntrained using traditional language modeling task of autocomplete (predict next word in sentence)\nonly attends to left context (previous tokens) during training (unidirectional)\ngenerative model that is stronger in tasks involving text generation\n\nThe genetic dogma\n\nbiological trajectory of a human or any other organism is a complex interplay between genetics+environment (DNA and environment individual is exposed to) aka genotype-phenotype-environment\ncentral dogma of molec bio describes flow of genetic info within living organisms\n\nsource of genetic info: our DNA (exact replica of which is harbored in nucleus of every cell in our body)\n\neach individual possesses 2 nearly identical copies of human genome (one from mom, one from dad)\n\n\nhuman chromosome structure: chromatin tightly packed in hierarchical coil structures. from bottom, 146 nucleotide pairs wrapped around histone (like a bead), and histones are coiled and supercoiled to form compact chromosome that fits within the nucleus of a cell\nwithin genome: ~20,000 genes (DNA segments accountable for protein synthesis)\n~1% of genome codes for proteins while remainder comprises regions controlling gene expression, regions within genes that don’t code for proteins, regions contributing to DNA structure, and “junk” regions of selfish DNA that have “learned” to self-replicate\ncentral dogma of molec bio maps out molec info flow from genome → expression of genes+subsequent production of proteins (building blocks of life)\ngenes expressed within cells by transcription (copies genes into single-stranded molecule mRNA) and translation (mRNA → amino acid protein sequence); 4-letter nucleotide code of DNA segment translated into 20-amino acid code of protein sequence; protein folds in 3d to form functional protein structure\ntranscription → splicing → translation\nsplicing: excised segments aka introns; kept regions aka exons make up protein-coding part of mRNA\n\neach mature mRNA assembled from ~7 exons\nvital in higher organisms b/c a single gene can yield multiple different proteins by assembling different exon combinations during splicing\n\n20,000 genes → 70,000 known standard splice forms+larger # rare/aberrant splice forms\nafter transcription, mRNA transported to cell’s protein-synthesizing machinery (ribosome) where translation occurs\n\nmRNA sequence decoded by codons (each corresponds to 1/20 amino acids)\n\namino acids linked together in a chain to form protein sequence → folds into functional, 3d protein structure\ngene regulation: intricate processes that dictate when/where/in what quantity genes are expressed within cell, ensuring timely production of the right proteins in the right amounts\n\ngene regulation takes place at various levels (structuring of chromatin, chem modifications, through action of specific proteins known as transcription factors) that recruit RNA polymerase and/control when/where/what amount gene will be expressed (requires open chromatin for transcription)\n\nTranscription factors (TFs): proteins in gene regulation that bind to distinct DNA sequences near/within genes (transcription factor binding sites) and influence recruitment of RNA polymerase, the enzyme tasked w/ mRNA synthesis\n\ntranscription factors modulate expression of target genes, guaranteeing appropriate gene expression in response to diverse cellular signals/environmental conditions\nTFs themselves modulated by TFs, forming complex gene regulatory pathways\n\nPromoters+enhancers: DNA regions that play a role in gene expression control\n\npromoters: located adjacent to start of a gene (upstream/to left of gene start, in chemical direction of DNA)\nenhancers: more distant regulatory elements situated within introns or between genes\nboth harbor several TF binding sites\nwith assistance of TFs, a gene’s promoter+enhancers form 3-d structures that recruit and regulate RNA polymerase responsible for mRNA synthesis\n\nChromatin structure: an amalgamation of DNA+proteins (histones) that constitute chromosomes\n\nto fit within each cell’s nucleus, DNA is wound around proteins known as histones\nhistones: tetramers (structures formed by assembling 4 copies of histone protein)\neach histone wraps around 146 nucleotide pairs of DNA, creating a rosary structure that subsequently folds into a higher order helical structure (chromatin)\nchromatin organization determines which DNA regions are accessible for gene expression\nfor gene expression to occur, chromatin must be unfolded\ntightly packed chromatin prevents gene expression\n\nHistone modifications: chemical modifications (e.g. acetylation/methylation) that can affect the histone beads+influence chromatin structure+gene accessibility\n\nmodifications can either promote or inhibit gene expression depending on type+location of modification\npart of the histone code (sort of epigenetic code) i.e. additional layer of code superimposed on the genetic code inscribed in the DNA\n\nDNA methylation: chem modification where methyl group added to DNA molec usually at specific cytosine bases\n\ncan influence gene expression by affecting binding of transcription factors or changing chromatin structure, making it more compact/less accessible for transcription\nalso part of epigenetic code\ngene regulation is a dynamic process specific to each cell type; diff cells exhibit unique gene expression profiles → perform specialized functions\nthrough precise control of gene expression cells can respond to enviro stimuli, sustain homeostasis+execute complex processes essential for life\n\nBidirectional flow of info: some exceptions to unidirectional flow of info (e.g. central dogma: DNA → RNA → protein):\n\nreverse transcription: RNA converted back to DNA; facilitated by reverse transcriptase+common in retroviruses such as HIV\nDNA can also be transcribed into RNA molec besides mRNA — tRNA, rRNA, and other types of non-coding RNA, adding another level of complexity to the flow of genetic information\nrole of epigenetics by DNA methylation and histone modification\n\n\nVariation in our DNA\n\nevery individual biologically shaped by interplay between DNA+enviro influences\nDNA variants account for heritability of all our traits\norigins of DNA variants\n\nprimary mechanism: mutations between genomes of 2 parents+germline genomes that both parents contribute to offspring’s genome\ndrive genetic variation+account for differences from other species\nmost new variants are benign\nsmaller fraction can be deleterious esp if they damage a functional region\neven smaller fraction could be beneficial\n\nSelection: deleterious variants/harmful genetic alterations render an organism less “fit” — tend to be statistically eliminated from population\n\nrare variants generally more likely to be harmful\n\nCoalescence+DNA sequence conservation: effects of selection are highly informative — 2 regions of similarity between genes eventually coalesce — eventually there is an ancestor mammalian individual that had 2 kids that both inherited precise same DNA piece, each leading to each gene today\n\nmutations that took place in important parts of gene tended to make individuals less fit\nmore conserved parts of DNA region more likely to be functionally imporant\n\nData generation: short DNA segments w/ a specific property of interest such as binding a certain TF or being part of the open accessible chromatin are isolated in an experiment+sequenced\n\nother technologies like MS and affinity-based proteomics can measure the levels of all proteins in a biological sample\nX-ray crystallography provides 3-d protein structures\n\nLinking variation to function: want to correlate genetic variants across individuals’ genomes w/ specific phenotypes (e.g. presence vs absence of a particular disease) aka GWAS\n\nidentify statistically significant associations of certain genome locations (which could be genes or regulatory regions) with the phenotypes under study\nwhen measured phenotype isn’t binary but a quantifiable entity, regression can be performed between genomic variation and phenotype, with identified genetic loci termed quantitative trait loci\nbesides macroscopic phenotypes (disease status, height, hair color), genetic variation can be associated w/ molecular phenotypes such as gene expression levels (leading to expression quantitative trait loci — eQTLs), protein abundance (results in protein quantitative trait loci — pQTLs) and virtually every other molecular measurement\nlikely to be surpassed by application of LLMs\n\nLanguage models in molec bio\n\nmodeling molec bio doesn’t need artificial general intelligence (AGI); i.e. doesn’t require high-level planning, agency, or goals; limited need for combinatorics+algorithmic reasoning\n\nrequires what LLMs are good at: learning stat properties of intricate, noisy sequential data to best predict such data from lossy representations\n\n\n\nPredicting gene structure\n\nprimary function of DNA: encode genes that are transcribed+translated into proteins\nspecific segments of each gene translated into proteins determined by splicing mechanisms (segments are annotated)\nmutations can disrupt precise boundaries of splicing (splice sites)\nrare mutations can significantly impact resulting protein fn+ produce a completely different protein sequence\n\naccount for 10% rare genetic diseases\n\nFundamental computational task: predicting splice sites+deducing gene structure; implications for diagnosing genetic diseases\n\naccuracy is not high enough\n\nSpliceAI: employs earlier techniques for language model (not transformer tech or LLM), where language is DNA sequences\n\ndeep residual CNN\ndilated convolutions to efficiently expand the window size it can handle\naccepts 10k nucleotide windows of human genome as input → predict exact locations of intron-exon boundaries (donor/acceptor sites) — exon-intron and intron-exon borders\nprecise-recall AUC: 0.98\naccurate enough to perform mutational analysis in silico — artificially laters any position of DNA and determines whether this change introduces or eliminates a splice site within 10k nucleotides of alteration\ncan be utilized to aid genetic diagnosis\nachieved high accuracy by learning biomolec properties of DNA sequence that guide splicing machinery to splice sites (previously less known)\nnew question: how to extract biomolec rules that SpliceAI learned+gain insight into underlying biomolec mechanisms?\n\nPredicting protein structure\n\nprotein sequences directly translated from spliced mRNA sequences according to genetic code, then fold into 3d structures\nwant to predict protein structure from protein sequence — difficult\nnew open-source database (AlphaFold2) that provides high-accuracy structural predictions for various organisms\n\nAlphaFold2 methodology:\n\ncombines CNN operating on protein sequences w/ pairwise co-evolution feature\nidentifies pairs of sequence positions that co-vary across related protein seuqneces in diff species to predict 2D contact maps across protein seuqnece\n\ncontact map: score for every pair of positions in sequence — likelihood of 2 positions being in close proximity in 3D\n\nbuilds on these algorithsms and introduces some new improvements:\n\nbased on transformer LLM architecture — can better capture long-range interactions between AA in protein seq\nnovel energy-based score (Amber energy) introduced to directly optimize 3d protein structure → allows for end-to-end differentiable approach during structure optimization step\nimproved utilization of coevolutionary features by incorporating multiple sequence alignment (MSA) data boosts model’s ability to identify conserved structural features across homologous protein sequences\nrefine: fine-tune predicted protein structures using second model trained on output of first model → more accurate and consistent predictions\n\nnote: ensemble?\n\n\n\n\nPredicting impact of protein variants\n\n4 million positions in genomes of any 2 individuals vary\n\n20k such variants located within protein-coding regions\nsmall fraction of genetic diversity is deleterious → contributes to genetic diseases\n\nclue in determining if a variant is benign: compare human genetics to genetics of close relatives\n\nproteins conserved by evolution are even more similar on average\n\nsearch for mutations that confer serious genetic disease should start from mutations not on this list\nuse list to observe patterns within protein seq and structures that tend to tolerate variants+patterns that tend not to tolerate variants\n\ncan gain ability to annotate variants in proteins as likely benign+likely pathogenic\n\nPrimateAI-3D: transformer that learns to distinguish between benign+pathogenic variants in human proteins\n\naccomplished by learning patterns of protein positions where primate variants tend to be present vs protein positions where they tend to be absent\nuses both protein seq data as well as protein 3D models that are either experimentally reconstructed or computationally predicted by tools like AlphaFold+HHpred\ncan be applied to diagnosis of rare disease+prioritize variants that are likely deleterious, filter out benign variants\nanother application: discovery of genes associated w/ complex diseases\n\nlook for variants likely deleterious according to PrimateAI-3D, then look for abundance of such variants within specific gene across cohort\ngenes with genetic “burden” (signal of playing role in the disease)\n\nused primate AI-3D+developed improved rare variant polygenic risk score models (PRS) to identify individuals at high diseases risk\n\n\nModeling gene regulation\n\nmolecular components: DNA chromatin structure, chemical alterations within histones that DNA wraps around, attachment of TFs to promoters+enhancers, establishment of 3D DNA structure involving promoters, enhancers, bound transcription factors, and recruitment of RNA polymerase\n\nData generation informative of gene regulation\n\nexamples of info obtained, always related to a human cell line or tissue type:\n\nidentify precise locations across entire genome that have open chromatin vs tightly packed chromatin\n\n2 relevant assays: DNAse-seq and ATAC-seq\n\npinpoint all locations in genome where a specific transcriptions factor is bound\nidentify all location in genome where a specific histone chem modification has occurred\ndetermining level of mRNA available for a given gene i.e. expression level of particular gene\n\nlanguage models → culminate in transformer-based Enformer tool\n\naccept DNA sequence near a gene as input, output cell type-specific expression level of this gene for any gene in the genome\ntrained on task: given a genome region of 100k nucleotides and a specific cell type, predict available types of experimental data for this region, including status of open/packed chromatin, present histone modifications, specific bound TFs, and level of gene expression\n\nlanguage model ideal (rather than masked language modeling) for supervised training — predict all tracks simultaneously from DNA seq\n\nincorporates attention mechanisms+collates info from distant regions to predict status of given location\n\nEnformer performs well in predicting gene exp from sequence alone\n\nhowever doesn’t achieve reduction of collecting necessary experimental data (highly correlated replicates of same experiment) yet\ncan predict changes in gene exp caused by mutations present in diff individuals as well as by mutations artificially introduced through CRISPR experiments\nlimitations: perform poorly in predicting effects of distal enhancers+correctly determine direction of effect of personal variants in gene expression\n\nOrca model: language model based on convolutional encoder-decoder architecture that predicts 3D genome structure from proximity data provided by Hi-C experiments\n\nhierarchical multi-level convolutional encoder, multilevel decoder, predicts DNA structure at 9 levels of resolution for input DNA seq that are as long as the longest human chromosome\n\n\nFoundation models\n\nlarge DL architectures (such as transformer-based GPT models by OpenAI) that encode a vast amount of knowledge\n\ncan be fine-tuned for specific tasks\n\n\nscGPT: foundation model designed for single-cell transcriptomics, chromatin accessibility, and protein abundance\n\ntrained on single-cell data from 10 million human cells\neach cell contains expression values for a fraction of ~20k human genes\nmodel learns embeddings of this large cell x gene matrix → provides insights into underlying cellular states+active bio pathways\nconcept of “next gene” is unclear in single-cell data\n\nsolution: train model to generate data based on a gene prompt (collection of known gene values)+cell prompt\nstarting from known genes, model predicts remaining genes along w/ conf values\nfor K iterations, divides those into K bins, and the top 1/K most confident genes are fixed as known genes for next iteration\n\nonce trained, fine-tune for numerous downstream tasks: batch correction, cell annotation (ground truth: annotated collections of diff cell types), perturbation prediction (predict cell state after a given set of genes are experimentally perturbed), multiomics (each layer, transcriptome, chromatin, proteome, treated as a different language)\n\nNucleotide transformer\n\nfoundational model that focuses on raw DNA sequences\nsequences tokenized into words of 6 characters each (k-mers of length 6)+trained using BERT methodlogy\ntraining dtaa: ref human genome, 3200 additional diverse human genomes, genomes of 850 other species\nnucleotide transformer applied to 18 downstream tasks that encompass many of previously discussed ones (promoter pred, splice site donor/acceptor pred, histone modifications, etc.)\npredictions made either through probing (embeddings at different layers used as features for simple classifiers — e.g. logistic regression+perceptrons) or light, computationally inexpensive fine-tuning\n\nLooking forward\n\nAGI not required (understanding molec bio/link to human health doesn’t need to be an AI task)\nasking AI to learn complex stat properties of existing biological systems\nexpect it to learn one-step causality relationships (mutation → malfunction)\n\nif gene is underexpressed, other genes in cascade in/decrease\ntriangulate between correlations across modalities such as DNA variation, protein abundance, and phenotype (Mendelian randomization) and large-scale perturbation experiments → LLM can model cellular states\ngenome ↔︎ phenotype\n\nsignificant gatekeeper: data\n\nUK Biobank Project (UKB)\n\nlarge-scale biobank, biomedical database+research resources containing comprehensive genetic/health info from 1/2 million UK participants\nlots of other large-scale data initiatives"
  },
  {
    "objectID": "posts/mx_alg_basics_pt1_post/index.html",
    "href": "posts/mx_alg_basics_pt1_post/index.html",
    "title": "Matrix algebra basics (numpy) - part 1",
    "section": "",
    "text": "from numpy import diag, array, eye, outer, trace, kron, allclose, linalg as la\n\nCreating a matrix\n\n\\[\n\\mathbf{L} = \\begin{pmatrix}    1&2&3\\\\    4&5&6\\end{pmatrix}\n\\]\nmx_L = array([[1,2,3],[4,5,6]])\n\nMatrix addition\n\n\\[\n\\begin{align*}\n\\mathbf{A} &=\n\\begin{pmatrix}\n1&2\\\\\n3&4\n\\end{pmatrix}\\\\\n\\mathbf{B} &=\n\\begin{pmatrix}\n5&6\\\\\n7&8\n\\end{pmatrix}\\\\\n\\mathbf{A}+\\mathbf{B} &=\n\\begin{pmatrix}\n6&8\\\\\n10&12\n\\end{pmatrix}\n\\end{align*}\n\\]\nmx_A = array([[1,2],[3,4]])\nmx_B = array([[5,6],[7,8]])\nmx_Y = mx_A+mx_B\n\nMatrix multiplication\n\n\\[\n\\mathbf{AB} =\n\\begin{pmatrix}\n19&22\\\\\n47&50\n\\end{pmatrix}\n\\]\nmx_F = mx_A.dot(mx_B)\n\nMatrix transpose\n\n\\[\n\\mathbf{A}^T =\n\\begin{pmatrix}\n1&3\\\\\n2&4\n\\end{pmatrix}\n\\]\nmx_A_t = mx_A.T\n\nIdentity matrix\n\n\\[\n\\mathbf{I} =\n\\begin{pmatrix}\n1&0&0\\\\\n0&1&0\\\\\n0&0&1\n\\end{pmatrix}\n\\]\nmx_I = eye(3,3)\n\nInverse matrix\n\n\\[\n\\begin{align*}\n\\mathbf{C} &=\n\\begin{pmatrix}\n1&2\\\\\n3&4\n\\end{pmatrix}\\\\\n\\mathbf{C}^{-1} &=\n\\begin{pmatrix}\n-2&1\\\\\n\\frac{3}{2}&\\frac{-1}{2}\n\\end{pmatrix}\\\\\n\\end{align*}\n\\]\nmx_C = array([[1,2],[3,4]])\nmx_C_inv = la.inv(mx_C)\n\nEigenvalues+eigenvectors (\\(\\lambda_i\\), \\(\\mathbf{x_i}\\))\n\n\\[\n\\mathbf{Cx} = \\lambda\\mathbf{x}\n\\]\nC_evals, C_evecs = la.eig(mx_C)\n\nMatrix reshape\n\n\\[\n\\begin{align*}\n\\mathbf{g} &=\n\\begin{pmatrix}\n1&2&3&4&5&6&7&8&9\n\\end{pmatrix}\\\\\n\\mathbf{G} &=\n\\begin{pmatrix}\n1&2&3\\\\\n4&5&6\\\\\n7&8&9\n\\end{pmatrix}\n\\end{align*}\n\\]\nvec_g = array([1,2,3,4,5,6,7,8,9])\nmx_G = vec_g.reshape(3,3)\n\nElement-wise matrix multiplication\n\n\\[\n\\mathbf{A}\\odot\\mathbf{B} =\n\\begin{pmatrix}\n5&12\\\\\n21&32\n\\end{pmatrix}\n\\]\nmx_H = mx_A*mx_B\n\nMatrix determinant\n\n\\[\n\\begin{align*}\n\\det(\\mathbf{C}) &=\n\\begin{vmatrix}\n\\mathbf{C}\n\\end{vmatrix}\\\\\n\\begin{vmatrix}\n1&2\\\\\n3&4\n\\end{vmatrix}\n&= -2\n\\end{align*}\n\\]\ndet_mx_C = la.det(mx_C)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tiffanie lab blog",
    "section": "",
    "text": "Conducting GWAS studies summary\n\n\n\n\n\n\n\nreadings\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\ntiffanie\n\n\n\n\n\n\n  \n\n\n\n\nPyTorch tutorial: tensor demo\n\n\n\n\n\n\n\ndemos\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\ntiffanie\n\n\n\n\n\n\n  \n\n\n\n\nMatrix algebra basics (numpy) - part 1\n\n\n\n\n\n\n\npractice\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\ntiffanie\n\n\n\n\n\n\n  \n\n\n\n\nLLM in molecular biology summary\n\n\n\n\n\n\n\nreadings\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\ntiffanie\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/conduct_gwas_post/index.html",
    "href": "posts/conduct_gwas_post/index.html",
    "title": "Conducting GWAS studies summary",
    "section": "",
    "text": "paper link\ndemo github link\n\n\nGlossary\n\n\nClumping: This is a procedure in which only the most significant SNP (i.e., lowest p value) in each LD block is identified and selected for further analyses. This reduces the correlation between the remaining SNPs, while retaining SNPs with the strongest statistical evidence.\nCo‐heritability: This is a measure of the genetic relationship between disorders. The SNP‐based co‐heritability is the proportion of covariance between disorder pairs (e.g., schizophrenia and bipolar disorder) that is explained by SNPs.\nGene: This is a sequence of nucleotides in the DNA that codes for a molecule (e.g., a protein)\nHeterozygosity: This is the carrying of two different alleles of a specific SNP. The heterozygosity rate of an individual is the proportion of heterozygous genotypes. High levels of heterozygosity within an individual might be an indication of low sample quality whereas low levels of heterozygosity may be due to inbreeding.\nIndividual‐level missingness: This is the number of SNPs that is missing for a specific individual. High levels of missingness can be an indication of poor DNA quality or technical problems.\nLinkage disequilibrium (LD): This is a measure of non‐random association between alleles at different loci at the same chromosome in a given population. SNPs are in LD when the frequency of association of their alleles is higher than expected under random assortment. LD concerns patterns of correlations between SNPs.\nMinor allele frequency (MAF): This is the frequency of the least often occurring allele at a specific location. Most studies are underpowered to detect associations with SNPs with a low MAF and therefore exclude these SNPs.\nPopulation stratification: This is the presence of multiple subpopulations (e.g., individuals with different ethnic background) in a study. Because allele frequencies can differ between subpopulations, population stratification can lead to false positive associations and/or mask true associations. An excellent example of this is the chopstick gene, where a SNP, due to population stratification, accounted for nearly half of the variance in the capacity to eat with chopsticks (Hamer & Sirota, 2000).\nPruning: This is a method to select a subset of markers that are in approximate linkage equilibrium. In PLINK, this method uses the strength of LD between SNPs within a specific window (region) of the chromosome and selects only SNPs that are approximately uncorrelated, based on a user‐specified threshold of LD. In contrast to clumping, pruning does not take the p value of a SNP into account.\nRelatedness: This indicates how strongly a pair of individuals is genetically related. A conventional GWAS assumes that all subjects are unrelated (i.e., no pair of individuals is more closely related than second‐degree relatives). Without appropriate correction, the inclusion of relatives could lead to biased estimations of standard errors of SNP effect sizes. Note that specific tools for analysing family data have been developed.\nSex discrepancy: This is the difference between the assigned sex and the sex determined based on the genotype. A discrepancy likely points to sample mix‐ups in the lab. Note, this test can only be conducted when SNPs on the sex chromosomes (X and Y) have been assessed.\nSingle nucleotide polymorphism (SNP): This is a variation in a single nucleotide (i.e., A, C, G, or T) that occurs at a specific position in the genome. A SNP usually exists as two different forms (e.g., A vs. T). These different forms are called alleles. A SNP with two alleles has three different genotypes (e.g., AA, AT, and TT).\nSNP‐heritability: This is the fraction of phenotypic variance of a trait explained by all SNPs in the analysis.\nSNP‐level missingness: This is the number of individuals in the sample for whom information on a specific SNP is missing. SNPs with a high level of missingness can potentially lead to bias.\nSummary statistics: These are the results obtained after conducting a GWAS, including information on chromosome number, position of the SNP, SNP(rs)‐identifier, MAF, effect size (odds ratio/beta), standard error, and p-value. Summary statistics of GWAS are often freely accessible or shared between researchers.\nThe Hardy–Weinberg (dis)equilibrium (HWE) law: This concerns the relation between the allele and genotype frequencies. It assumes an indefinitely large population, with no selection, mutation, or migration. The law states that the genotype and the allele frequencies are constant over generations. Violation of the HWE law indicates that genotype frequencies are significantly different from expectations (e.g., if the frequency of allele A = 0.20 and the frequency of allele T = 0.80; the expected frequency of genotype AT is 2 * 0.2 * 0.8 = 0.32) and the observed frequency should not be significantly different. In GWAS, it is generally assumed that deviations from HWE are the result of genotyping errors. The HWE thresholds in cases are often less stringent than those in controls, as the violation of the HWE law in cases can be indicative of true genetic association with disease risk.\n\n\nIntro\nAim of genome-wide association studies (GWAS): to identify single nucleotide polymorphisms (SNPs — variation in single nucleotide at specific position in genome; exists as 2 forms aka alleles) of which allele frequencies vary systematically as a fn of phenotypic trait values, since identifying trait-associated SNPs may reveal new insights into biological mechanisms behind phenotypes. SNP w/ 2 alleles → 3 different genotypes.\nHistorically studies suggest that psychiatric traits are influenced by SNPs — each having small individual effect sizes. GWAS relies strongly on in-depth knowledge of genetic architecture of the human genome, provided by the International HapMap Project (patterns of common SNPs within human DNA seq)+1000 Genomes project (map of both common and rare SNPs).\nGWAS results showed effect sizes of individual SNPs are small → want to find way to aggregate effect of SNPs → focus on PRS (polygenic risk score) analysis, since it can be applied to target samples w/ more modest sample sizes.\nPRS — combines effect sizes of multiple SNPs into an aggregated score (individual level, based on # risk variants carried, weighted by SNP effect sizes from an independent large-scaled discovery GWAS) used to predict disease risk.\n\ni.e. indication of total genetic risk for an individual for a specific trait (disease status); can be used in clinical pred/screening\nsignificantly associaed w/ case-control status for psychiatric traits; however discriminative accuracy still insufficient\nalso used to investigate if genetic effect sizes from a GWAS of a specific phenotype of interest can predict risk of another phenotype\npaper outline: quality control (QC) procedures before GWAS, commonly used tests of association, conduct analysis\n\nSoftware\nPLINK v1.08 will be used for QC procedures+stat analyses and R for visualization.\nPLINK: reads text-format or binary files, but binary is faster and recommended\n\ntext PLINK data: 2 files of different contents\n\ninfo on individuals+genotype (*.ped)\ninfo on genetic markers (*.map)\n\nbinary PLINK data: 3 files\n\nbinary file w/ IDs+genotypes for individuals (*.bed)\n\ne.g. individual IDs and genotypes\n\ntext file w/ info on individuals (*.fam)\n\ne.g. subject-related data like family relationship w/ other participants, sex, clinical diagnosis\n\ntext file w/ info on genetic markers (*.bim)\n\ne.g. info on phys position of SNPs\n\n\n\n\n\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6001694/bin/MPR-27-e1608-g001.jpg\n\n\nPLINK — command line program → requires active shell waiting for commands\n\nafter prompt: indicate use of PLINK w/ plink (will need path to directory if not in current directory)\nafter plink other options, beginning w/ 2 dashes -- :\n\nprovide format+name of data files\n\ntext file: --file {your_file}\nbinary: --bfile {yourfile}\n\nafter: other options can be added; e.g. --assoc option for association analysis w/ \\(\\chi^2\\) test for each SNP to phenotype of interest\n\nmultiple options can be combined in a single command line, but default order is implemented\n--out {outfile} provides name to output file\n\nQC of genetic data\nAppropriate QC needed to generate reliable results since sources of errors include poor quality of DNA samples, poor DNA hybridization to array, poorly performing genotype probes, and sample mix-ups/contamination.\nData simulation w/ HapMap data:\n\nillustration of analysis steps w/ realistic genetic data using simulated dataset (\\(N=207\\)) w/ binary outcome measure\nrelatively small sample size+ethnically homogeneous dataset (*larger sample sizes will be needed to detect genetic risk factors of complex traits)\ndata from demo 1 in this md file (link)\n\n7 QC steps (key terms from beginning bolded) — hands-on lab in demos 1+2\n\nindividual+SNP missingness\ninconsistencies in assigned+genetic sex of subjects (see sex discrepancy)\nminor allele freq (MAF)\ndeviations from HWE (Hardy-Weinberg equilibrium)\nheterozygosity rate\nrelatedness\nethnic outliers (see population stratification)\n\nStep - command - fn - threshold table\n\n\n\n\n\n\n\n\n\nStep\nCommand\nFn\nThreshold\n\n\n\n\nmissingness of SNPs+individuals\n--geno, --mind\nexcludes SNPs missing in large proportion of subjects, remove SNPs w/ low genotype calls*; excludes individuals w/ high rates of genotype missingness, remove individual with low genotype calls\nrecommended: first filter SNPs+individuals based on relaxed threshold (0.2; &gt;20%) to filter out ones w/ very high levels of missingness; then apply filter w/ more stringent threshold (0.02);\n\n\nSNP filtering before individual filtering\n\n\n\n\n\nsex discrepancy\n--check-sex\nchecks for sex discrepancies between individuals recorded in dataset+sex based on X chromosome heterozygosity/homozygosity rates\ncan indicate sample mix-ups; want to see males X chromosome homozygosity estimate of &gt;0.8 and females of &lt;0.2\n\n\nMAF (minor allele freq)\n--maf\ninclude only SNPs above set MAF threshold\nSNPs w/ low MAF are rare → power lacking for detecting SNP-phenotype associations; SNPs also more prone to genotyping errors; MAF threshold depends on sample size — larger samples can use lower MAF thresholds; for large (\\(N = 100.000\\)) vs. moderate samples (\\(N = 10000\\)), 0.01 and 0.05 are commonly used as MAF threshold\n\n\nHWE\n--hwe\nexclude markers deviating from HWE\ncommon indicator of genotyping error; may also indicate evolutionary selection. binary traits — suggest excluding HWE where \\(p&lt;1\\times10^{-10}\\) in cases, \\(p&lt;1\\times10^{-6}\\) in controls; less strict case threshold avoids discarding disease-associated SNPs under selection; quantitative traits — recommend HWE \\(p &lt; 1\\times10^{-6}\\)\n\n\nheterozygosity\nscript from demo link\nexclude individuals w/ high or low heterozygosity rates\ndeviations can indicate sample contamination, inbreeding; suggest removing individuals deviating \\(\\pm 3s_x\\) from the samples’ heterozygosity rate mean.\n\n\nrelatedness\n--genome, --min\ncalculate identity by descent (IBD)** of all sample pairs, creates list of individuals w/ relatedness above set threshold**\nuse independent SNPs (pruning) for this analysis+limit to autosomal chromosomes only; cryptic relatedness can interfere with the association analysis — if you have a family-based sample (e.g., parent-offspring), don’t need to remove related pairs but should take family relatedness into account. for a population based sample suggested threshold is \\(\\hat{\\pi}=0.2\\)\n\n\npopulation stratification\n--genome, --cluster --mds-plot k\ncalculates IBD** of all sample pairs; produces \\(k\\)-dimensional representation of any substructure in data based on IBS\n\\(K\\)= # dimensions (to be defined; usually 10)\n\n\n\n\n*genotype calls: estimation of one unique SNP or genotype\n**identity by descent: matching segment of DNA shared by two or more people that has been inherited from a common ancestor without any intervening recombination\n\nControlling for population stratification\npopulation stratification: presence of multiple subpopulations (e.g., individuals with different ethnic background) in a study\n\ncan lead to false (+) associations and/or mask true associations\ne.g. chopstick gene (where a SNP due to population stratification accounted for nearly half of the variance in capacity to eat w. chopsticks)\nmay exist even within a single ethnic population\n\nOne method to correct: multidimensional scaling (MDS) approach — calculate genome-wide average proportion of alleles shared between any pair of individuals within sample to generate quantitative indices (components) of genetic variation for each individual. Individual component scores can be plotted to explore whether there are groups of individuals that are genetically more similar to each other than expected.\n\nplot scores of sample under investigation+population of known ethnic structure (such as HapMap/1KG data) — anchoring\nenables researcher to obtain ethnic info on their sample+determine possible ethnic outliers\noutliers can be removed; conduct new MDS analysis\n\nmain components used as covariates in association tests in order to correct for any remaining population stratification in population\n\n\n\n\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6001694/bin/MPR-27-e1608-g003.jpg\n\n\nStatistical tests of association\nAfter QC+calculation of MDS components, select appropriate statistical test:\n\n1 df allelic test (trait value or log-odds of a binary trait increases linearly as a function of number of risk alleles — minor allele a vs major allele A)\n\neach allele becomes the statistical unit instead of an individual (main problem with this approach is that we would be ignoring the induced correlation in the data by the fact that we are, in some sense, “double counting” the observations)\n\nnon-additive tests*\n\ngenotypic association test (2 df — aa vs Aa vs AA)\ndominant gene action test (1 df — [aa & Aa] vs AA)\nrecessive gene action test (1 df — aa vs [Aa & AA])\n*not widely applied b/c power to detect non-additivity is low\n\n\nBinary outcome measure\n\nassociation between SNPs and a binary outcome (1=unaffected; 2=affected; 0/-9=missing) tested with --assoc (\\(\\chi^2\\) test of association — cannot include covariates) or --logistic (logistic regression analysis — allows covariates but more computational time)\n\nQuantitative outcome measure\n\nassociation between SNPs and quantitative outcome measures can be tested w/ assoc (automatically treats as numerical by performing asymptotic version of student’s \\(t\\) test to compare 2 means) and --linear (linear regression analysis w/ each individual SNP as a predictor; enables use of covariates but slower)\n\nCorrection for multiple testing\n\nmultiple testing burden since genotyping arrays can genotype up to 4 million markers concurrently, generating large # of tests\n3 widely applied alternatives for determining genome-wide significance:\n\nBonferroni: good for controlling Type I error rate; adjusted p w/ formula \\(\\frac{\\alpha}{n}\\) (where \\(\\alpha\\) is original p-value; here it is 0.05 and \\(n\\) is # SNPs tested)\n\nmany SNPs correlated due to linkage disequilibrium (LD) and thus not independent — too harsh of a correction and could lead to increase in proportion of false negative findings\n\nBenjamini-Hochberg: controls expected proportion of FP among all signals with FDR value below fixed threshold\n\nFDR method assumes SNPs are independent\nlimitation: SNPs and thus p values are not independent\n\n\n\n--adjust outputs unadjusted p value along w/ p values corrected w/ various multiple testing correction methods\n\n\npermutation methods: outcome measure labels randomly permuted mutiple times to remove any true association between outcome measure and genotype\n\nstatistical tests performed for all permuted datasets; compare empirical distribution of test statistic and p values under null to original test statistic\n--assoc and --mperm combined to generate 2 p-values: EMP1 (empirical p value — uncorrected) and EMP2 (empirical p value corrected for multiple testing)\n\n\n\nPRS analysis\nComputing a PRS\n\nsingle variant association analysis is the primary methdo in GWAS but needs large sample size to detect SNPs for many complex traits\nPRS aggregates genetic risk across genome in single individual polygenic score for a trait of interest\nlarge discovery sample required to reliably dtermine how much each SNP is expected to contribute to polygenic score (”weights”) of a specific trait\nin an independent target sample (doesn’t need to be as big) polygenic scores calculated based on genetic DNA profiles+these weights — around 200 subjects provides sufficient power to detect significan proportion of variance explained\ndiscovery+target samples should have same # subjects until the target sample includes 2,000 subjects\nmore available samples → additional subjects should be included in discovery sample to maximize accuracy of estimation of effect sizes\nhas been successfully used to show significant associations both within+across traits\n\ne.g. a significant association with disease risk was found despite fact that the available sample sizes were too small to detect genome-wide significant SNPs\n\n\n\n\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6001694/bin/MPR-27-e1608-g004.jpg\n\n\n\nto conduct PRS analysis, trait specific weights (\\(\\beta\\)s for continuous traits+log of odds ratio for binary traits) are obtained from a discovery GWAS\n\nin target sample, PRS is calculated for each individual based on weighted sum of # risk alleles that he or she carries multiplied by trait-specific weights (SNP effect sizes publicly available for many complex traits)\n\nall common SNPs could be used in a PRS analysis, but it is customary to clump first (only the most significant SNP (i.e., lowest p* value) in each LD block is identified and selected for further analyses) the GWAS results, then compute risk scores\np value thresholds typically used to remove SNPs that show little or no statistical evidence for association\nmultiple PRS analyses will be performed with varying thresholds for p values\n\nConducting polygenic risk prediction analyses\n\nonce PRS has been calculated for all subjects in target sample, use scores in logistic reg analysis → predict trait expected to show genetic overlap w/ trait of interest\n\nprediction accuracy expressed w/ \\(R^2\\) measure of regression analysis (include at least a few MDS components as covariates in regression analysis to control for population stratification)\n\nto estimate how much variation is explained by PRS, \\(R^2\\) of a model that includes covariates+PRS will be compared\n\nincrease in \\(R^2\\) due to PRS indicates increase in prediction accuracy explained by genetic risk factors\n\nprediction accuracy of PRS depends mostly on (co-)heritability of analyzed traits, the number of SNPs, and the size of discovery sample\n\nsize of target sample only affects reliability of \\(R^2\\)"
  }
]